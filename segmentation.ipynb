{"cells":[{"cell_type":"markdown","metadata":{},"source":["> **Requirements and Uploading datasets**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install monai\n","#!pip install scikit-image==0.19.3\n","#!pip install networkx\n","#!pip install gdown --upgrade"]},{"cell_type":"markdown","metadata":{},"source":["> **Train the basic model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# full_debugged_unet3d_train.py\n","import os\n","import glob\n","import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","\n","from monai.transforms import (\n","    LoadImaged,\n","    Orientationd,\n","    Spacingd,\n","    ScaleIntensityRanged,\n","    CropForegroundd,\n","    RandCropByPosNegLabeld,\n","    EnsureChannelFirstd,\n","    Compose,\n",")\n","from monai.data import DataLoader, Dataset, NibabelReader\n","from monai.inferers import sliding_window_inference\n","from monai.metrics import DiceMetric\n","from monai.losses import DiceCELoss\n","from monai.config import print_config\n","from monai.utils import set_determinism\n","\n","import torch.nn.functional as F\n","from torch.cuda import amp\n","\n","# ---------------------------\n","\n","class SingleConv(torch.nn.Sequential):\n","    def __init__(self, in_channels, out_channels, kernel_size, order='crg', GroupNumber=8):\n","        super(SingleConv, self).__init__()\n","        for name, module in self._create_conv(in_channels, out_channels, kernel_size, order, GroupNumber):\n","            self.add_module(name, module)\n","\n","    def _create_conv(self, in_channels, out_channels, kernel_size, order, GroupNumber):\n","        assert 'c' in order, 'Convolution must have a conv operation'\n","        modules = []\n","        for i, char in enumerate(order):\n","            if char == 'r':\n","                modules.append(('ReLU', torch.nn.ReLU(inplace=True)))\n","            elif char == 'c':\n","                bias = not ('g' in order or 'b' in order)\n","                modules.append(('conv', torch.nn.Conv3d(in_channels, out_channels, kernel_size, bias=bias, padding=1, stride=1)))\n","            elif char == 'g':\n","                is_before_conv = i < order.index('c')\n","                assert not is_before_conv, 'GroupNorm MUST go after the Conv3d'\n","                if out_channels < GroupNumber:\n","                    GroupNumber = out_channels\n","                modules.append(('groupnorm', torch.nn.GroupNorm(num_groups=GroupNumber, num_channels=out_channels)))\n","            elif char == 'i':\n","                modules.append(('instancenorm', torch.nn.InstanceNorm3d(out_channels, affine=True)))\n","            elif char == 'b':\n","                modules.append(('batchnorm', torch.nn.BatchNorm3d(out_channels)))\n","        return modules\n","\n","class DoubleConv(torch.nn.Sequential):\n","    def __init__(self, in_channels, out_channels, kernel_size, encoder, order='crg', GroupNumber=8):\n","        super(DoubleConv, self).__init__()\n","        if encoder:\n","            conv1_in_channels = in_channels\n","            conv1_out_channels = out_channels // 2\n","            if (conv1_out_channels < in_channels):\n","                conv1_out_channels = in_channels\n","            conv2_in_channels, conv2_out_channels = conv1_out_channels, out_channels\n","        else:\n","            conv1_in_channels, conv1_out_channels = in_channels, out_channels\n","            conv2_in_channels, conv2_out_channels = out_channels, out_channels\n","        self.add_module(name='Conv1', module=SingleConv(in_channels=conv1_in_channels,\n","                                                       out_channels=conv1_out_channels,\n","                                                       kernel_size=kernel_size,\n","                                                       order=order,\n","                                                       GroupNumber=GroupNumber))\n","        self.add_module(name='Conv2', module=SingleConv(in_channels=conv2_in_channels,\n","                                                       out_channels=conv2_out_channels,\n","                                                       kernel_size=kernel_size,\n","                                                       order=order,\n","                                                       GroupNumber=GroupNumber))\n","\n","class UNet3D_Encoder(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3, pool_kernelsize=(2, 2, 2),\n","                     pooling_type='max', apply_pooling=True, Basic_Module=DoubleConv, order='crg', GroupNumber=8):\n","        super(UNet3D_Encoder, self).__init__()\n","        assert pooling_type in ['max', 'avg'], 'Pooling_Type must be max or avg'\n","        if apply_pooling:\n","            if pooling_type == 'max':\n","                self.pooling = torch.nn.MaxPool3d(kernel_size=pool_kernelsize)\n","            else:\n","                self.pooling = torch.nn.AvgPool3d(kernel_size=pool_kernelsize)\n","        else:\n","            self.pooling = None\n","        self.basic_module = Basic_Module(in_channels=in_channels,\n","                                             out_channels=out_channels,\n","                                             kernel_size=kernel_size,\n","                                             encoder=True, order=order,\n","                                             GroupNumber=GroupNumber)\n","\n","    def forward(self, x):\n","        if self.pooling is not None:\n","            x = self.pooling(x)\n","        x = self.basic_module(x)\n","        return x\n","\n","class UNet3D_Decoder(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3, Basic_Module=DoubleConv, order='crb', GroupNumber=8):\n","        super(UNet3D_Decoder, self).__init__()\n","        self.upsample = None\n","        self.basic_module = Basic_Module(in_channels=in_channels,\n","                                             out_channels=out_channels,\n","                                             kernel_size=kernel_size,\n","                                             encoder=False, order=order,\n","                                             GroupNumber=GroupNumber)\n","\n","    def forward(self, encoder_feature, x):\n","        output_size = encoder_feature.size()[2:]\n","        x = F.interpolate(input=x, size=output_size, mode='trilinear', align_corners=True)\n","        x = torch.cat((encoder_feature, x), dim=1)\n","        x = self.basic_module(x)\n","        return x\n","\n","class UNet3D(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels, finalsigmoid, fmaps_degree, GroupNormNumber,\n","                     fmaps_layer_number, layer_order, device, **kwargs):\n","        super(UNet3D, self).__init__()\n","        self.device = device\n","        assert isinstance(fmaps_degree, int), 'fmaps_degree must be an integer!'\n","        fmaps_list = [fmaps_degree * 2 ** k for k in range(fmaps_layer_number)]\n","\n","        self.EncoderLayer1 = UNet3D_Encoder(in_channels=in_channels, out_channels=fmaps_list[0], apply_pooling=False,\n","                                                 Basic_Module=DoubleConv, order=layer_order,\n","                                                 GroupNumber=GroupNormNumber).to(self.device)\n","        self.EncoderLayer2 = UNet3D_Encoder(in_channels=fmaps_list[0], out_channels=fmaps_list[1], apply_pooling=True,\n","                                                 Basic_Module=DoubleConv, order=layer_order,\n","                                                 GroupNumber=GroupNormNumber).to(self.device)\n","        self.EncoderLayer3 = UNet3D_Encoder(in_channels=fmaps_list[1], out_channels=fmaps_list[2], apply_pooling=True,\n","                                                 Basic_Module=DoubleConv, order=layer_order,\n","                                                 GroupNumber=GroupNormNumber).to(self.device)\n","        self.EncoderLayer4 = UNet3D_Encoder(in_channels=fmaps_list[2], out_channels=fmaps_list[3], apply_pooling=True,\n","                                                 Basic_Module=DoubleConv, order=layer_order,\n","                                                 GroupNumber=GroupNormNumber).to(self.device)\n","\n","        DecoderFmapList = list(reversed(fmaps_list))\n","\n","        self.DecoderLayer1 = UNet3D_Decoder(in_channels=DecoderFmapList[0] + DecoderFmapList[1],\n","                                                 out_channels=DecoderFmapList[1],\n","                                                 Basic_Module=DoubleConv, order=layer_order, GroupNumber=GroupNormNumber).to(\n","            self.device)\n","        self.DecoderLayer2 = UNet3D_Decoder(in_channels=DecoderFmapList[1] + DecoderFmapList[2],\n","                                                 out_channels=DecoderFmapList[2],\n","                                                 Basic_Module=DoubleConv, order=layer_order, GroupNumber=GroupNormNumber).to(\n","            self.device)\n","        self.DecoderLayer3 = UNet3D_Decoder(in_channels=DecoderFmapList[2] + DecoderFmapList[3],\n","                                                 out_channels=DecoderFmapList[3],\n","                                                 Basic_Module=DoubleConv, order=layer_order, GroupNumber=GroupNormNumber).to(\n","            self.device)\n","\n","        self.final_conv = torch.nn.Conv3d(in_channels=fmaps_list[0], out_channels=out_channels, kernel_size=1).to(\n","            self.device)\n","\n","        if finalsigmoid:\n","            self.final_activation = torch.nn.Sigmoid().to(self.device)\n","        else:\n","            self.final_activation = torch.nn.Softmax(dim=1).to(self.device)\n","\n","    def forward(self, x):\n","        encoder_features = []\n","        x1 = self.EncoderLayer1(x)\n","        encoder_features.insert(0, x1.to(self.device))\n","        x2 = self.EncoderLayer2(x1)\n","        encoder_features.insert(0, x2)\n","        x3 = self.EncoderLayer3(x2)\n","        encoder_features.insert(0, x3)\n","        x4 = self.EncoderLayer4(x3)\n","\n","        x = self.DecoderLayer1(encoder_features[0], x4)\n","        x = self.DecoderLayer2(encoder_features[1], x).to(self.device)\n","        x = self.DecoderLayer3(encoder_features[2], x)\n","\n","        x = self.final_conv(x)\n","        if not self.training:\n","            x = self.final_activation(x)\n","        return x\n","\n","# ---------------------------\n","\n","set_determinism(seed=0)\n","print_config()\n","\n","\n","image_folder = \"/kaggle/input/images\"\n","label_folder = \"/kaggle/input/labels/Labels\"\n","\n","images = sorted(glob.glob(os.path.join(image_folder, \"**\", \"*.nii*\"), recursive=True))\n","labels = sorted(glob.glob(os.path.join(label_folder, \"**\", \"*.nii*\"), recursive=True))\n","\n","def basename_noext(path):\n","    base = os.path.basename(path)\n","    if base.endswith('.nii.gz'):\n","        return base[:-7]\n","    return os.path.splitext(base)[0]\n","\n","img_dict = {basename_noext(p): p for p in images}\n","lbl_dict = {basename_noext(p): p for p in labels}\n","common_keys = sorted(set(img_dict.keys()).intersection(set(lbl_dict.keys())))\n","if len(common_keys) == 0:\n","    raise ValueError(\"No matched image/label pairs found. Check paths and filenames.\")\n","\n","all_data = [{\"image\": img_dict[k], \"label\": lbl_dict[k]} for k in common_keys]\n","train_size = int(0.8 * len(all_data))\n","train_data_dicts = all_data[:train_size]\n","val_data_dicts = all_data[train_size:]\n","\n","\n","train_transforms = Compose([\n","    LoadImaged(keys=[\"image\", \"label\"], reader=NibabelReader()),\n","    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n","    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n","    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n","    ScaleIntensityRanged(keys=[\"image\"], a_min=-1000, a_max=400, b_min=0.0, b_max=1.0, clip=True),\n","    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n","\n","    RandCropByPosNegLabeld(keys=[\"image\", \"label\"], label_key=\"label\", spatial_size=(96, 96, 96),\n","                           pos=1, neg=1, num_samples=2, image_key=\"image\", image_threshold=0),\n","])\n","\n","val_transforms = Compose([\n","    LoadImaged(keys=[\"image\", \"label\"], reader=NibabelReader()),\n","    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n","    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n","    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n","    ScaleIntensityRanged(keys=[\"image\"], a_min=-1000, a_max=400, b_min=0.0, b_max=1.0, clip=True),\n","    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n","])\n","\n","train_ds = Dataset(data=train_data_dicts, transform=train_transforms)\n","val_ds = Dataset(data=val_data_dicts, transform=val_transforms)\n","\n","\n","DEFAULT_BATCH_SIZE = 1  \n","cpu_count = os.cpu_count() or 1\n","num_workers = min(4, max(0, cpu_count - 1))\n","pin_memory = True if torch.cuda.is_available() else False\n","\n","train_loader = DataLoader(train_ds, batch_size=DEFAULT_BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n","val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=max(0, num_workers-1), pin_memory=pin_memory)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}, batch_size={DEFAULT_BATCH_SIZE}, num_workers={num_workers}, pin_memory={pin_memory}\")\n","\n","\n","model = UNet3D(in_channels=1, out_channels=1, finalsigmoid=True,\n","               fmaps_degree=32, GroupNormNumber=8, fmaps_layer_number=4, layer_order='crg',\n","               device=device)\n","\n","model = model.to(device)\n","\n","loss_function = DiceCELoss(to_onehot_y=False, sigmoid=True)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","# mixed precision scaler\n","use_amp = True if torch.cuda.is_available() else False\n","scaler = amp.GradScaler(enabled=use_amp)\n","\n","# number of epochs\n","epochs = 110\n","\n","os.makedirs(\"logs\", exist_ok=True)\n","os.makedirs(\"models\", exist_ok=True)\n","epoch_losses = []\n","\n","\n","def save_model_cpu(model, epoch, folder=\"models\"):\n","    path = os.path.join(folder, f\"unet3d_epoch_{epoch}.pth\")\n","\n","    state = {k: v.cpu() for k, v in model.state_dict().items()}\n","    torch.save(state, path)\n","    print(f\"Saved model checkpoint for epoch {epoch} -> {path}\")\n","   \n","def plot_prediction_vs_gt(val_images, val_labels, prediction, epoch, show=True, save_fig=False, out_folder=\"logs\"):\n","    image_np = val_images.cpu().squeeze().numpy()\n","    label_np = val_labels.cpu().squeeze().numpy()\n","    prediction_np = prediction.cpu().squeeze().numpy()\n","    (D, H, W) = image_np.shape\n","    axial_slice = D // 2\n","    sagittal_slice = W // 2\n","    coronal_slice = H // 2\n","\n","    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n","    fig.suptitle(f'Prediction vs Ground Truth - Epoch {epoch}', fontsize=14)\n","\n","    axes[0, 0].imshow(image_np[axial_slice, :, :], cmap='gray'); axes[0, 0].set_title('Image (Axial)')\n","    axes[0, 1].imshow(label_np[axial_slice, :, :], cmap='jet'); axes[0, 1].set_title('GT (Axial)')\n","    axes[0, 2].imshow(prediction_np[axial_slice, :, :], cmap='jet'); axes[0, 2].set_title('Pred (Axial)')\n","\n","    axes[1, 0].imshow(image_np[:, :, sagittal_slice], cmap='gray'); axes[1, 0].set_title('Image (Sagittal)')\n","    axes[1, 1].imshow(label_np[:, :, sagittal_slice], cmap='jet'); axes[1, 1].set_title('GT (Sagittal)')\n","    axes[1, 2].imshow(prediction_np[:, :, sagittal_slice], cmap='jet'); axes[1, 2].set_title('Pred (Sagittal)')\n","\n","    axes[2, 0].imshow(image_np[:, coronal_slice, :], cmap='gray'); axes[2, 0].set_title('Image (Coronal)')\n","    axes[2, 1].imshow(label_np[:, coronal_slice, :], cmap='jet'); axes[2, 1].set_title('GT (Coronal)')\n","    axes[2, 2].imshow(prediction_np[:, coronal_slice, :], cmap='jet'); axes[2, 2].set_title('Pred (Coronal)')\n","\n","    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","    if save_fig:\n","        os.makedirs(out_folder, exist_ok=True)\n","        figpath = os.path.join(out_folder, f\"prediction_vs_gt_epoch_{epoch}.png\")\n","        fig.savefig(figpath)\n","        print(f\"Saved comparison figure: {figpath}\")\n","    if show:\n","        plt.show()\n","    plt.close(fig)\n","\n","\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","\n","\n","torch.backends.cudnn.benchmark = True\n","\n","print(\"Starting training...\")\n","for epoch in range(epochs):\n","    model.train()\n","    epoch_loss = 0.0\n","    step = 0\n","    pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n","    for batch_idx, batch_data in enumerate(pbar):\n","        inputs = batch_data[\"image\"].to(device)\n","        labels = batch_data[\"label\"].to(device)\n","\n","        \n","        optimizer.zero_grad(set_to_none=True)\n","\n","        try:\n","            with amp.autocast(enabled=use_amp):\n","                outputs = model(inputs)\n","                loss = loss_function(outputs, labels)\n","\n","            # scale & backward\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","\n","\n","            step += 1\n","            epoch_loss += loss.item()\n","            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n","\n","            del outputs, loss\n","            torch.cuda.empty_cache()\n","\n","        except RuntimeError as e:\n","\n","            if 'out of memory' in str(e).lower():\n","                print(f\"WARNING: CUDA OOM on batch {batch_idx+1} of epoch {epoch+1}. Skipping this batch.\")\n","                torch.cuda.empty_cache()\n","\n","                optimizer.zero_grad(set_to_none=True)\n","                continue\n","            else:\n","                raise\n","\n","    if step == 0:\n","        avg_epoch_loss = float(\"nan\")\n","        print(\"Warning: no successful training steps in this epoch (all batches failed?).\")\n","    else:\n","        avg_epoch_loss = epoch_loss / step\n","\n","    print(f\"Epoch {epoch + 1} average loss: {avg_epoch_loss:.4f}\")\n","\n","    \n","    epoch_losses.append(avg_epoch_loss)\n","    df_partial = pd.DataFrame({\"epoch\": list(range(1, len(epoch_losses) + 1)), \"loss\": epoch_losses})\n","    df_partial.to_csv(\"logs/epoch_losses.csv\", index=False)\n","\n","\n","    save_model_cpu(model, epoch + 1, folder=\"models\")\n","\n","\n","    if (epoch + 1) % 10 == 0:\n","        model.eval()\n","        dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n","        with torch.no_grad():\n","            for vbatch in tqdm(val_loader, desc=\"Validation\"):\n","                val_images = vbatch[\"image\"].to(device)\n","                val_labels = vbatch[\"label\"].to(device)\n","                with amp.autocast(enabled=use_amp):\n","                    val_outputs = sliding_window_inference(val_images, (96, 96, 96), 2, model, overlap=0.5)\n","                val_outputs = (val_outputs > 0.5).float()\n","                dice_metric(y_pred=val_outputs, y=val_labels)\n","                del val_outputs\n","                torch.cuda.empty_cache()\n","            try:\n","                mean_dice = dice_metric.aggregate().item()\n","                dice_metric.reset()\n","                print(f\"Validation Dice Score at epoch {epoch + 1}: {mean_dice:.4f}\")\n","            except Exception:\n","                print(\"Validation metric aggregation failed or no valid predictions.\")\n","\n","\n","    if (epoch + 1) % 5 == 0:\n","        if len(val_loader) == 0:\n","            print(\"No validation data for visual comparison.\")\n","        else:\n","            model.eval()\n","            with torch.no_grad():\n","                try:\n","                    val_batch = next(iter(val_loader))\n","                    val_images = val_batch[\"image\"].to(device)\n","                    val_labels = val_batch[\"label\"].to(device)\n","                    with amp.autocast(enabled=use_amp):\n","                        val_outputs = sliding_window_inference(val_images, (96, 96, 96), 2, model, overlap=0.5)\n","                    prediction = (val_outputs > 0.5).float()\n","\n","\n","                    show_img = val_images[0] if val_images.shape[0] > 1 else val_images\n","                    show_lbl = val_labels[0] if val_labels.shape[0] > 1 else val_labels\n","                    show_pred = prediction[0] if prediction.shape[0] > 1 else prediction\n","\n","                    plot_prediction_vs_gt(show_img, show_lbl, show_pred, epoch + 1, show=True, save_fig=True, out_folder=\"logs\")\n","\n","                    del val_outputs, prediction\n","                    torch.cuda.empty_cache()\n","                except Exception as e:\n","                    print(\"Visual comparison failed:\", e)\n","                    torch.cuda.empty_cache()\n","\n","\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","\n","df = pd.DataFrame({\"epoch\": list(range(1, len(epoch_losses) + 1)), \"loss\": epoch_losses})\n","df.to_csv(\"logs/epoch_losses.csv\", index=False)\n","print(\"Training finished. Saved epoch losses to logs/epoch_losses.csv\")\n","\n","\n","final_model_path = os.path.join(\"models\", \"unet3d_last_epoch.pth\")\n","save_model_cpu(model, \"final\", folder=\"models\")\n","print(\"Done.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install scikit-image==0.19.3\n","!pip install networkx\n","!pip install gdown --upgrade\n","!pip install skimage"]},{"cell_type":"markdown","metadata":{},"source":["> **Transformer model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","from einops import rearrange\n","import numpy as np\n","import torch.nn.functional as F\n","\n","\n","def pair(t):\n","    return t if isinstance(t, tuple) else (t, t)\n","\n","\n","class PreNorm(nn.Module):\n","    def __init__(self, dim, fn):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(dim)\n","        self.fn = fn\n","\n","    def forward(self, x, **kwargs):\n","        return self.fn(self.norm(x), **kwargs)\n","\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, dim, hidden_dim, dropout=0.):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dim, dim),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","\n","class Attention_spd(nn.Module):\n","    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n","        super().__init__()\n","        inner_dim = dim_head * heads\n","        project_out = not (heads == 1 and dim_head == dim)\n","\n","        self.heads = heads\n","        self.scale = dim_head ** -0.5\n","\n","        self.attend = nn.Softmax(dim=-1)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n","\n","        self.to_out = nn.Sequential(\n","            nn.Linear(inner_dim, dim),\n","            nn.Dropout(dropout)\n","        ) if project_out else nn.Identity()\n","\n","    def forward(self, x, spd, p, attn_mask=None):\n","        qkv = self.to_qkv(x).chunk(3, dim=-1)\n","        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n","        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale + spd\n","        attn = self.attend(dots)\n","        attn = self.dropout(attn)\n","\n","        mask = torch.ones_like(attn, requires_grad=False)\n","        a = np.random.binomial(1, 1 - p, size=mask.shape[1])\n","        while np.sum(a) == 0:\n","            a = np.random.binomial(1, 1 - p, size=mask.shape[1])\n","        for i in range(mask.shape[1]):\n","            if a[i] == 0:\n","                mask[:, i, :, :] = 0\n","\n","        attn = attn * mask * mask.shape[1] / np.sum(a)  # normalization\n","\n","        if attn_mask is not None:\n","            attn = attn * attn_mask\n","\n","        out = torch.matmul(attn, v)\n","        out = rearrange(out, 'b h n d -> b n (h d)')\n","        return self.to_out(out)\n","\n","\n","class Transformer_postnorm_spd(nn.Module):\n","    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(dim)\n","        self.layers = nn.ModuleList([])\n","        for _ in range(depth):\n","            self.layers.append(nn.ModuleList([\n","                Attention_spd(dim, heads=heads, dim_head=dim_head, dropout=dropout),\n","                FeedForward(dim, mlp_dim, dropout=dropout)\n","            ]))\n","\n","    def forward(self, x, spd, p, attn_mask=None):\n","        for attn, ff in self.layers:\n","            x = attn(x, spd, p, attn_mask) + x\n","            x = self.norm(x)\n","            x = ff(x) + x\n","            x = self.norm(x)\n","        return x\n","\n","\n","class learnabel_mask(nn.Module):\n","    def __init__(self, dim=128):\n","        super().__init__()\n","        self.softmax = nn.Softmax(dim=-1)\n","        self.pairwise_processor = PairwiseProcessing(dim)\n","        self.mlp = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, 1), \n","            nn.Sigmoid()  \n","        )\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x, toplogy_mask):\n","        K = self.mlp(x).repeat(1, 1, x.shape[1])  # 1*N*N\n","        x = x.squeeze(0)\n","        xpair1 = x.unsqueeze(0).repeat(x.shape[0], 1, 1)  # N*N*d\n","        xpair2 = x.unsqueeze(1).repeat(1, x.shape[0], 1)  # N*N*d\n","        nodepair = torch.cat([xpair1, xpair2], 2)  # N*N*2d\n","        nodepair = nodepair.unsqueeze(0).permute(0, 3, 1, 2).contiguous()  # 1*2d*N*N\n","        nodepair = self.pairwise_processor(nodepair)  # Process pairwise features\n","        nodepair = nodepair.permute(0, 2, 3, 1).contiguous()  # 1*N*N*2\n","        nodepair = self.softmax(nodepair)[:, :, :, 0]\n","        nodepair = toplogy_mask * (nodepair + (1 - nodepair) * K) + (1 - toplogy_mask) * nodepair\n","        return nodepair\n","\n","\n","class Attention_cross(nn.Module):\n","    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n","        super().__init__()\n","        inner_dim = dim_head * heads\n","        project_out = not (heads == 1 and dim_head == dim)\n","\n","        self.heads = heads\n","        self.scale = dim_head ** -0.5\n","\n","        self.attend = nn.Softmax(dim=-1)\n","        self.dropout = nn.Dropout(dropout)\n","        self.to_q = nn.Linear(dim, inner_dim, bias=False)\n","        self.to_kv = nn.Linear(dim, inner_dim * 2, bias=False)\n","\n","        self.to_out = nn.Sequential(\n","            nn.Linear(inner_dim, dim),\n","            nn.Dropout(dropout)\n","        ) if project_out else nn.Identity()\n","\n","    def forward(self, x1, x2, spd=None):\n","        q = self.to_q(x1)\n","        q = rearrange(q, 'b n (h d) -> b h n d', h=self.heads)\n","        kv = self.to_kv(x2).chunk(2, dim=-1)\n","        k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.heads), kv)\n","        if spd is None:\n","            dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n","        else:\n","            dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale + spd\n","        attn = self.attend(dots)\n","        attn = self.dropout(attn)\n","\n","        out = torch.matmul(attn, v)\n","        out = rearrange(out, 'b h n d -> b n (h d)')\n","        return self.to_out(out)\n","\n","\n","class Transformer_postnorm_cross_spd(nn.Module):\n","    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(dim)\n","        self.layers = nn.ModuleList([])\n","        for _ in range(depth):\n","            self.layers.append(nn.ModuleList([\n","                Attention_spd(dim, heads=heads, dim_head=dim_head, dropout=dropout),\n","                FeedForward(dim, mlp_dim, dropout=dropout)\n","            ]))\n","        self.cross = Attention_cross(dim, heads=heads, dim_head=dim_head, dropout=dropout)\n","\n","    def forward(self, x, x2, spd=None, p=0, attn_mask=None):\n","        if spd is not None:\n","            for attn, ff in self.layers:\n","                x = attn(x, spd, p, attn_mask) + x\n","                x = self.norm(x)\n","                x = ff(x) + x\n","                x = self.norm(x)\n","                x = self.cross(x, x2, spd) + x\n","                x = self.norm(x)\n","        return x\n","\n","\n","class Attention_cross_base(nn.Module):\n","    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n","        super().__init__()\n","        inner_dim = dim_head * heads\n","        project_out = not (heads == 1 and dim_head == dim)\n","\n","        self.heads = heads\n","        self.scale = dim_head ** -0.5\n","\n","        self.attend = nn.Softmax(dim=-1)\n","        self.dropout = nn.Dropout(dropout)\n","        self.to_q = nn.Linear(dim, inner_dim, bias=False)\n","        self.to_kv = nn.Linear(dim, inner_dim * 2, bias=False)\n","\n","        self.to_out = nn.Sequential(\n","            nn.Linear(inner_dim, dim),\n","            nn.Dropout(dropout)\n","        ) if project_out else nn.Identity()\n","\n","    def forward(self, x1, x2):\n","        q = self.to_q(x1)\n","        q = rearrange(q, 'b n (h d) -> b h n d', h=self.heads)\n","        kv = self.to_kv(x2).chunk(2, dim=-1)\n","        k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.heads), kv)\n","\n","        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n","        attn = self.attend(dots)\n","        attn = self.dropout(attn)\n","        out = torch.matmul(attn, v)\n","        out = rearrange(out, 'b h n d -> b n (h d)')\n","        return self.to_out(out)\n","\n","\n","class Transformer_postnorm_cross(nn.Module):  \n","    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(dim)\n","        self.layers = nn.ModuleList([])\n","        for _ in range(depth):\n","            self.layers.append(nn.ModuleList([\n","                Attention_cross_base(dim, heads=heads, dim_head=dim_head, dropout=dropout),\n","                FeedForward(dim, mlp_dim, dropout=dropout)\n","            ]))\n","\n","    def forward(self, x, x2):\n","        for attn, ff in self.layers:\n","            x = attn(x, x2) + x\n","            x = self.norm(x)\n","            x = ff(x) + x\n","            x = self.norm(x)\n","        return x\n","\n","\n","class PairwiseProcessing(nn.Module):\n","    def __init__(self, dim):\n","        super().__init__()\n","        self.pairbn0 = nn.BatchNorm2d(dim * 2)\n","        self.pairbn1 = nn.BatchNorm2d(dim)\n","        self.pairbn2 = nn.BatchNorm2d(dim // 2)\n","        self.pairbn3 = nn.BatchNorm2d(dim // 4)\n","        self.pairbn4 = nn.BatchNorm2d(dim // 8)\n","\n","        self.pairconv10 = nn.Conv2d(dim * 2, dim * 2, kernel_size=1, bias=False)\n","        self.pairconv11 = nn.Conv2d(dim * 2, dim, kernel_size=1, bias=False)\n","        self.pairconv20 = nn.Conv2d(dim, dim, kernel_size=1, bias=False)\n","        self.pairconv21 = nn.Conv2d(dim, dim // 2, kernel_size=1, bias=False)\n","        self.pairconv3 = nn.Conv2d(dim // 2, dim // 4, kernel_size=1, bias=False)\n","        self.pairconv4 = nn.Conv2d(dim // 4, dim // 8, kernel_size=1, bias=False)\n","        self.pairconv5 = nn.Conv2d(dim // 8, 2, kernel_size=1, bias=False)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, nodepair):\n","        nodepair = self.pairbn0(nodepair)  # 1*d*N*C 128\n","        nodepair = self.relu(self.pairbn1(self.pairconv11(self.relu(self.pairconv10(nodepair)))))  # 1*64*N*C\n","        nodepair = self.relu(self.pairbn2(self.pairconv21(self.relu(self.pairconv20(nodepair)))))  # 1*32*N*C\n","        nodepair = self.relu(self.pairbn3(self.pairconv3(nodepair)))  # 1*16*N*C\n","        nodepair = self.relu(self.pairbn4(self.pairconv4(nodepair)))  # 1*8*N*C\n","        nodepair = self.pairconv5(nodepair)  # 1*2*N*C\n","        return nodepair\n","\n","\n","class Outlier_detect(nn.Module):\n","    def __init__(self, depth, dim, heads, mlp_dim, dim_head=64, prototype_class=22, dropout=0., ):\n","        super().__init__()\n","        self.alpha = nn.Parameter(torch.ones(1))\n","        self.pairwise_processor = PairwiseProcessing(dim)\n","        self.softmax = nn.Softmax(dim=-1)\n","        self.mlp = nn.Sequential(\n","            nn.LayerNorm(prototype_class * 2),\n","            nn.Linear(prototype_class * 2, 1),  \n","            nn.Sigmoid()  \n","        )\n","        self.relu = nn.ReLU(inplace=True)\n","        self.Trans_cross = Transformer_postnorm_cross(dim, depth, heads, dim_head, mlp_dim, dropout)\n","\n","    def forward(self, x, logits):\n","        S = F.softmax(logits, dim=-1)\n","        S = S ** self.alpha\n","        H = torch.matmul(S.transpose(-1, -2), x)\n","        H = self.Trans_cross(H, x)\n","\n","        x = x.squeeze(0)\n","        H = H.squeeze(0)\n","        xpair1 = H.unsqueeze(0).repeat(x.shape[0], 1, 1)  # N*C*d\n","        xpair2 = x.unsqueeze(1).repeat(1, H.shape[0], 1)  # N*C*d\n","        nodepair = torch.cat([xpair1, xpair2], 2)  # N*C*2d\n","        nodepair = nodepair.unsqueeze(0).permute(0, 3, 1, 2).contiguous()  # 1*2d*N*C\n","        nodepair = self.pairwise_processor(nodepair)  # Process pairwise features\n","        nodepair = nodepair.permute(0, 2, 3, 1).contiguous()  # 1*N*C*2\n","        nodepair = nodepair.view(nodepair.shape[0], nodepair.shape[1], -1)  # 1*N*2C\n","        outlier = self.mlp(nodepair)\n","        return outlier\n","\n","\n","class Stage_independent(nn.Module):\n","    def __init__(self, depth, outlier_depth, num_classes1, num_classes2, num_classes3, dim, heads, mlp_dim, dim_head=64,\n","                 dropout=0., ):\n","        super().__init__()\n","        hierarchy = [depth, depth, depth, depth]\n","        self.transformer = nn.ModuleList([])\n","        self.dense_linear = nn.ModuleList(\n","            [nn.Linear((i + 1) * dim, dim) for i in range(len(hierarchy))]\n","        )\n","        for d in hierarchy:\n","            self.transformer.append(\n","                Transformer_postnorm_spd(dim, d, heads, dim_head, mlp_dim, dropout)\n","            )\n","        self.att_mask = learnabel_mask(dim=dim)\n","        self.mlp_head1 = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, num_classes1)\n","        )\n","\n","        self.mlp_head2 = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, num_classes2)\n","        )\n","        self.mlp_head3 = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, num_classes3)\n","        )\n","        self.outlier = Outlier_detect(outlier_depth, dim, heads, mlp_dim, dim_head=64, dropout=0.,\n","                                      prototype_class=num_classes2)\n","        self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, x, spd, p, toplogy_mask):\n","\n","        x_ = []\n","        list = []\n","        list.append(x)\n","        pred_ = []\n","        for i in range(len(self.transformer) - 1):\n","            x = self.dense_linear[i](torch.cat(list, dim=-1))\n","            if i == 0:\n","                x = self.transformer[i](x, spd[i], p, None)\n","                pred = self.mlp_head1(x)\n","            if i == 1:\n","                x = self.transformer[i](x, spd[i], p, None)\n","                pred = self.mlp_head2(x)\n","                nodepair = self.att_mask(x, toplogy_mask)\n","                prior = self.softmax(nodepair)\n","                pred = torch.matmul(prior, pred)\n","                outlier = self.outlier(x, pred)\n","                outlier_mask = 1 - (\n","                        outlier.repeat(1, 1, x.shape[1]) - outlier.transpose(1, 2).repeat(1, x.shape[1], 1)) ** 2\n","\n","            if i == 2:\n","                x = self.transformer[i](x, spd[i], p, nodepair * outlier_mask)  \n","                x = self.transformer[i + 1](x, spd[i], p, None)\n","                pred = self.mlp_head3(x)\n","            x_.append(x)\n","            list.append(x)\n","            pred_.append(pred)\n","        return x_[0], x_[1], x_[2], pred_[0], pred_[1], pred_[2], nodepair, outlier\n","\n","\n","class Stage_guided(nn.Module):\n","    def __init__(self, input_depth, outlier_depth, num_classes1, num_classes2, num_classes3, dim, heads, mlp_dim,\n","                 dim_head=64,\n","                 dropout=0.):\n","        super().__init__()\n","        hierarchy = [input_depth, input_depth, input_depth, input_depth]\n","        self.transformer = nn.ModuleList([])\n","        self.dense_linear = nn.ModuleList(\n","            [nn.Linear((i + 1) * dim, dim) for i in range(len(hierarchy))]\n","        )\n","        layer_num = 0\n","        for d in hierarchy:\n","            if layer_num >= 2:\n","                self.transformer.append(\n","                    Transformer_postnorm_spd(dim, d, heads, dim_head, mlp_dim, dropout)\n","                )\n","            else:\n","                self.transformer.append(\n","                    Transformer_postnorm_cross_spd(dim, d, heads, dim_head, mlp_dim, dropout)\n","                )\n","            layer_num += 1\n","        self.att_mask = learnabel_mask(dim=dim)\n","        self.mlp_head1 = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, num_classes1)\n","        )\n","\n","        self.mlp_head2 = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, num_classes2)\n","        )\n","        self.mlp_head3 = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, num_classes3)\n","        )\n","\n","        self.outlier = Outlier_detect(outlier_depth, dim, heads, mlp_dim, dim_head=64, dropout=0.,\n","                                      prototype_class=num_classes2)\n","        self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, x, spd, x2, p, toplogy_mask, outlier):\n","        x_ = []\n","        list = []\n","        list.append(x)\n","        pred_ = []\n","        for i in range(len(self.transformer) - 1):\n","            x = self.dense_linear[i](torch.cat(list, dim=-1))\n","            if i == 0:\n","                x = self.transformer[i](x, x2[i], spd[i], p, None)\n","                pred = self.mlp_head1(x)\n","            if i == 1:\n","                x = self.transformer[i](x, x2[i], spd[i], p, None)\n","                pred = self.mlp_head2(x)\n","                nodepair = self.att_mask(x, toplogy_mask)\n","                prior = self.softmax(nodepair)\n","                pred = torch.matmul(prior, pred)\n","                outlier = self.outlier(x, pred)\n","                outlier_mask = 1 - (outlier.repeat(1, 1, x.shape[1]) - outlier.transpose(1, 2).repeat(1, x.shape[1],\n","                                                                                                      1)) ** 2\n","            if i == 2:\n","                x = self.transformer[i](x, spd[i], p, nodepair * outlier_mask)\n","                x = self.transformer[i + 1](x, spd[i], p, None)\n","                pred = self.mlp_head3(x)\n","            x_.append(x)\n","            list.append(x)\n","            pred_.append(pred)\n","\n","        return x_[0], x_[1], x_[2], pred_[0], pred_[1], pred_[2], nodepair, outlier\n","\n","\n","class our_net(nn.Module):\n","    def __init__(self, input_dim, num_classes1, num_classes2, num_classes3, dim, heads, mlp_dim, dim_head=64,\n","                 dropout=0., trans_depth=2, outlier_depth=2):\n","        super().__init__()\n","\n","        self.accecpt = Stage_guided(trans_depth, outlier_depth, num_classes1, num_classes2, num_classes3, dim, heads,\n","                                    mlp_dim,\n","                                    dim_head=dim_head,\n","                                    dropout=dropout)\n","\n","        self.give = Stage_independent(trans_depth, outlier_depth, num_classes1, num_classes2, num_classes3, dim, heads,\n","                                      mlp_dim, dim_head=dim_head,\n","                                      dropout=dropout)\n","\n","        self.to_embedding = nn.Sequential(nn.Linear(input_dim, dim))\n","        self.spatial_pos_encoders = nn.ModuleList([nn.Embedding(30, heads, padding_idx=0) for _ in range(3)])\n","        self.softmax = nn.Softmax(dim=-1)\n","\n","    def _get_dict(self, spd):\n","        \"\"\"Encodes spatial position and prepares the dict.\"\"\"\n","        return [encoder(spd).permute(0, 3, 1, 2) for encoder in self.spatial_pos_encoders]\n","\n","    def forward(self, x, toplogy_mask, spd, p):\n","        x = self.to_embedding(x).unsqueeze(0)\n","        spd = spd.unsqueeze(0)\n","        dict = self._get_dict(spd)\n","\n","        # First stage\n","        feature1_1, feature2_1, feature3_1, x1_1, x2_1, x3_1, node_pair1, outlier_1 = self.give(x, dict, p,\n","                                                                                                toplogy_mask)\n","\n","        # Cross-stage input\n","        x_cross = [feature2_1, feature3_1]\n","        feature1_2, feature2_2, feature3_2, x1_2, x2_2, x3_2, node_pair2, outlier_2 = self.accecpt(x, dict, x_cross, p,\n","                                                                                                   toplogy_mask, None)\n","\n","        # Process and return outputs\n","        x1_1 = x1_1.squeeze(0)\n","        x2_1 = x2_1.squeeze(0)\n","        x3_1 = x3_1.squeeze(0)\n","        node_pair1 = node_pair1.squeeze(0)\n","        outlier_1 = outlier_1.squeeze(0)\n","        outlier_1 = outlier_1.squeeze(-1)\n","\n","        node_pair2 = node_pair2.squeeze(0)\n","        x1_2 = x1_2.squeeze(0)\n","        x2_2 = x2_2.squeeze(0)\n","        x3_2 = x3_2.squeeze(0)\n","        outlier_2 = outlier_2.squeeze(0)\n","        outlier_2 = outlier_2.squeeze(-1)\n","        return x1_1, x2_1, x3_1, x1_2, x2_2, x3_2, node_pair1, node_pair2, outlier_1, outlier_2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import networkx as nx\n","import torch\n","import numpy as np\n","\n","def extract_graph_features_for_transformer(airway_graph):\n","    node_features = []\n","    \n","    if airway_graph.number_of_nodes() > 0:\n","        for node_id, data in airway_graph.nodes(data=True):\n","            pos = data['pos']\n","            node_features.append(list(pos))\n","            \n","    return torch.tensor(node_features, dtype=torch.float32)\n","\n","def generate_topology_mask(airway_graph, max_nodes):\n","    adj_matrix = nx.to_numpy_array(airway_graph, nodelist=sorted(airway_graph.nodes()))\n","    \n","    padded_adj_matrix = np.zeros((max_nodes, max_nodes), dtype=np.float32)\n","    padded_adj_matrix[:adj_matrix.shape[0], :adj_matrix.shape[1]] = adj_matrix\n","    \n","    topology_mask = torch.tensor(padded_adj_matrix, dtype=torch.bool)\n","    \n","    return topology_mask\n","\n","def process_with_transformer(airway_graph, transformer_model):\n","    max_nodes = 100 \n","    \n","    node_features = extract_graph_features_for_transformer(airway_graph)\n","    \n","    if node_features.shape[0] > max_nodes:\n","        node_features = node_features[:max_nodes]\n","    \n","    num_nodes = node_features.shape[0]\n","    \n","    padded_node_features = torch.zeros(max_nodes, node_features.shape[1], dtype=torch.float32)\n","    padded_node_features[:num_nodes, :] = node_features\n","    \n","    topology_mask = generate_topology_mask(airway_graph, max_nodes)\n","    \n","    spd = torch.rand(num_nodes, max_nodes, 4)\n","    p = torch.zeros(num_nodes, dtype=torch.long)\n","    \n","    with torch.no_grad():\n","        output = transformer_model(x=padded_node_features, toplogy_mask=topology_mask, spd=spd, p=p)\n","        \n","    return output\n","\n","if 'airway_graph' in locals():\n","    print(\"Preparing graph data for transformer...\")\n","    \n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    \n","    from transformer import Transformer_postnorm_spd\n","    \n","    transformer_model = Transformer_postnorm_spd(\n","        dim=3, heads=4, dim_head=64, mlp_dim=128, dropout=0.1, attention_dropout=0.1\n","    ).to(device)\n","    \n","    graph_output = process_with_transformer(airway_graph, transformer_model)\n","    \n","    print(\"Transformer output shape:\", [o.shape for o in graph_output])\n","else:\n","    print(\"The variable 'airway_graph' was not found. Please run the graph generation code first.\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":8061933,"sourceId":12752999,"sourceType":"datasetVersion"},{"datasetId":8063140,"sourceId":12976855,"sourceType":"datasetVersion"},{"datasetId":8224212,"sourceId":12993106,"sourceType":"datasetVersion"}],"dockerImageVersionId":31090,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"}},"nbformat":4,"nbformat_minor":4}
